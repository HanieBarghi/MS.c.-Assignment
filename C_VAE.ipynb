{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "C-VAE.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CjyMzxPJR_a",
        "colab_type": "text"
      },
      "source": [
        "# C-VAE for MNIST\n",
        "\n",
        "For further information read the [Conditional Variational Autoencoder tutorial](https://wiseodd.github.io/techblog/2016/12/17/conditional-vae/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUqx4y8uJR_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-Pvhl2mJR_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set Hyper-parameters (change None)\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-3\n",
        "N_EPOCH = 50\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSeYSr78JR_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST Dataset\n",
        "original_train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "original_test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=original_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=original_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjzRAxFLJR_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, x_dim, z_dim, c_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        \n",
        "        # encoder \n",
        "        self.f1 = nn.Linear(x_dim + c_dim, 512)\n",
        "        self.f2 = nn.Linear(512, 256)\n",
        "        self.f3 = nn.Linear(256, z_dim)\n",
        "        self.f4 = nn.Linear(256, z_dim)\n",
        "        \n",
        "        # decoder \n",
        "        self.f5 = nn.Linear(z_dim + c_dim, 256)\n",
        "        self.f6 = nn.Linear(256, 512)\n",
        "        self.f7 = nn.Linear(512, x_dim)\n",
        "\n",
        "    def encoder(self, x, c):\n",
        "        inp = torch.cat([x, c], 1)\n",
        "        x = self.f1(inp)\n",
        "        x = F.relu(x)\n",
        "        x = self.f2(x)\n",
        "        x = F.relu(x)\n",
        "        out1 = self.f3(x)\n",
        "        out2 = self.f4(x) \n",
        "        return out1, out2 \n",
        "    \n",
        "    def decoder(self, z, c):\n",
        "        inp = torch.cat([z, c], 1)\n",
        "        x = self.f5(inp)\n",
        "        x = F.relu(x)\n",
        "        x = self.f6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.f7(x)\n",
        "        out = F.sigmoid(x)\n",
        "        return out    \n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = log_var.mul(0.5).exp_()\n",
        "        eps = torch.autograd.Variable(std.data.new(std.size()).normal_())\n",
        "        return eps.mul(std).add(mu)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, c):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784), c)\n",
        "        z = self.sampling(mu, log_var)\n",
        "        out1 = self.decoder(z, c)\n",
        "        return out1, mu, log_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN6C3tmGJR_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Model (change None)\n",
        "cond_dim = 10\n",
        "latent_dim = 2\n",
        "cvae = CVAE(x_dim=784, z_dim=latent_dim, c_dim=cond_dim)\n",
        "\n",
        "# Device setting\n",
        "cvae = cvae.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJgM_3JWJSAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Model\n",
        "cvae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5SoMPHtJSAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(cvae.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    recon_loss = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    return 1 * kl_loss + 0.05 * recon_loss #You can change constants"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QJdXu3CJSAT",
        "colab_type": "code",
        "outputId": "7ccefd14-75cc-4b61-d412-c932094161cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# Train\n",
        "def one_hott(cond):\n",
        "    OH = torch.zeros((cond.shape[0], 10))\n",
        "    OH[torch.arange(cond.shape[0]), cond] = 1\n",
        "    return OH\n",
        "    \n",
        "for epoch in range(1, N_EPOCH + 1):\n",
        "    cvae.train()\n",
        "    train_loss = 0\n",
        "    for (data, cond) in train_loader:\n",
        "        data = data.to(device)\n",
        "        \n",
        "        cond = one_hott(cond) # create one-hot condition\n",
        "        cond = cond.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, log_var = cvae(data, cond)\n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch: {}/{}\\t Average loss: {:.4f}'.format(epoch, N_EPOCH, train_loss / len(train_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50\t Average loss: 9.3158\n",
            "Epoch: 2/50\t Average loss: 8.6708\n",
            "Epoch: 3/50\t Average loss: 8.5730\n",
            "Epoch: 4/50\t Average loss: 8.5031\n",
            "Epoch: 5/50\t Average loss: 8.4700\n",
            "Epoch: 6/50\t Average loss: 8.4509\n",
            "Epoch: 7/50\t Average loss: 8.4404\n",
            "Epoch: 8/50\t Average loss: 8.4359\n",
            "Epoch: 9/50\t Average loss: 8.4276\n",
            "Epoch: 10/50\t Average loss: 8.4269\n",
            "Epoch: 11/50\t Average loss: 8.4266\n",
            "Epoch: 12/50\t Average loss: 8.4199\n",
            "Epoch: 13/50\t Average loss: 8.4247\n",
            "Epoch: 14/50\t Average loss: 8.4162\n",
            "Epoch: 15/50\t Average loss: 8.4174\n",
            "Epoch: 16/50\t Average loss: 8.4135\n",
            "Epoch: 17/50\t Average loss: 8.4164\n",
            "Epoch: 18/50\t Average loss: 8.4139\n",
            "Epoch: 19/50\t Average loss: 8.4041\n",
            "Epoch: 20/50\t Average loss: 8.4109\n",
            "Epoch: 21/50\t Average loss: 8.4102\n",
            "Epoch: 22/50\t Average loss: 8.4076\n",
            "Epoch: 23/50\t Average loss: 8.4085\n",
            "Epoch: 24/50\t Average loss: 8.4070\n",
            "Epoch: 25/50\t Average loss: 8.4097\n",
            "Epoch: 26/50\t Average loss: 8.4055\n",
            "Epoch: 27/50\t Average loss: 8.4001\n",
            "Epoch: 28/50\t Average loss: 8.4051\n",
            "Epoch: 29/50\t Average loss: 8.4052\n",
            "Epoch: 30/50\t Average loss: 8.4022\n",
            "Epoch: 31/50\t Average loss: 8.3993\n",
            "Epoch: 32/50\t Average loss: 8.4014\n",
            "Epoch: 33/50\t Average loss: 8.3970\n",
            "Epoch: 34/50\t Average loss: 8.3980\n",
            "Epoch: 35/50\t Average loss: 8.3982\n",
            "Epoch: 36/50\t Average loss: 8.3962\n",
            "Epoch: 37/50\t Average loss: 8.3968\n",
            "Epoch: 38/50\t Average loss: 8.3964\n",
            "Epoch: 39/50\t Average loss: 8.3993\n",
            "Epoch: 40/50\t Average loss: 8.3957\n",
            "Epoch: 41/50\t Average loss: 8.3931\n",
            "Epoch: 42/50\t Average loss: 8.3999\n",
            "Epoch: 43/50\t Average loss: 8.3987\n",
            "Epoch: 44/50\t Average loss: 8.3909\n",
            "Epoch: 45/50\t Average loss: 8.3962\n",
            "Epoch: 46/50\t Average loss: 8.3897\n",
            "Epoch: 47/50\t Average loss: 8.3900\n",
            "Epoch: 48/50\t Average loss: 8.3967\n",
            "Epoch: 49/50\t Average loss: 8.3963\n",
            "Epoch: 50/50\t Average loss: 8.3957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N_g54FUJSAV",
        "colab_type": "code",
        "outputId": "d00887cd-8cbd-4c9b-a62b-cfea65668409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit_size = 28\n",
        "z_sample = torch.randn(1, 2) # random \n",
        "plt.figure(figsize=(20, 1))\n",
        "\n",
        "for i in range(10):\n",
        "    c = torch.zeros((1, 10))\n",
        "    c[0][i] = 1\n",
        "    \n",
        "    cvae.eval()\n",
        "    with torch.no_grad():\n",
        "        z_sample = z_sample.to(device)\n",
        "        c = c.to(device)\n",
        "        img = cvae.decoder(z_sample, c)\n",
        "        # reshape (if needed)\n",
        "        img = img.detach().cpu().view(28, 28).numpy()\n",
        "\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap='Greys_r',)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABEIAAABECAYAAACF1JB3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2d3ZNU1fmF10DP8OGMDCAIYkgwfIUB\nVKIRMf40uUgqlYtUqpI/MlepSlKpslJlTIoyEeVzRvxAIIAiGI0GFBFl+ndBPfucWU0zMz2nxzC9\nnpu2e3p68Lz97r3Pu9Z+91C73VYIIYQQQgghhBDCILDs2/4HhBBCCCGEEEIIISwWKYSEEEIIIYQQ\nQghhYEghJIQQQgghhBBCCANDCiEhhBBCCCGEEEIYGFIICSGEEEIIIYQQwsDQutcPh4aGluyRMu12\ne+jb/jcsFonj/U9iuDRIHO9/EsOlQeJ4/5MYLg0Sx/ufxHBpMIhxjCMkhBBCCCGEEEIIA8M9HSEh\nhBBCCCEMCkNDQ/d8Xqfdbs94DCGEcP8QR0gIIYQQQgghhBAGhjhCQhggli27U/tE4fJHqVPh6vYY\nQggh3O8w/w0PD0uSHnjgAUnS2NiYJOnBBx/UQw89JElqte4sm2/duiVJ+s9//iNJ+uSTTyRJn3/+\nuSTpyy+/lCTdvn1bUubNEEL4XySOkBBCCCGEEEIIIQwMi+oIoeqOKr18+fLyfHp6WlKn6szrPIb/\nXequAv7bVZCoIosDOYZ6tXr1aknSmjVrJN1RuCRp/fr1kqQVK1aU96N0Xb9+XZL02WefSZI+/fTT\nGa/zvihei0c3Jw/xhna7HUfPEuJePQruRWK9+NwtR92J5/nq8f3mm28kda6DksPNwnVnnsQJsmHD\nBknSjh07yuN3v/tdSdLKlSslSVeuXJEkvfPOO5Kkc+fOSZIuXbokSfr6668lda5dE7sQmsXHz+RY\nmA9xhIQQQgghhBBCCGFg6KsjBNUDtZn9lps3b5Yk7dmzR5K0ZcuW8rNr165Jki5fvixJmpqakiRd\nvXpVUrX/8ubNm5LiFPk2wdEzPj4uSdq1a5f27t0rSRoZGZEkvfnmm5KkyclJSZW7AMUrNAs5h2qF\n82PLli2SpJ07d0qStm3bJkn6/ve/L0navn27JGl0dLRU0z/++GNJleJFLr799tuSpDNnzkiS/vvf\n/0qSvvrqK0nJySZw1xzxZJwk5x5++GFJnc6e5cuXlz3qxPH999+XVO1pv3HjhqTK2eOqc+gP3dw8\n/jg9PV1iwXv5PvCIkg2Mq/4Y11bzeExwE+C+Gx0dLY/kJ6+Rz3wG8WFdQ86yHsKFx/qH57gOEtfe\ncEcI8dm6daskad++fZKkAwcOlNc8Jndz49U/u5s7NoTQia99fDx96KGHirOZvP3iiy8kVeMmzxkv\nWeO40y45+e3yv+LkiSMkhBBCCCGEEEIIA0NfHCHuBEG1fPrppyVJP/vZzyRJP/rRjyRJjzzySOnW\njYrJ/svDhw9Lkv72t79Jko4ePSpJ+uijj2a8Pyr04uEd1tlP+8wzz+j//u//JFVOBFSyf//735Kq\nSm0UymYhJjhxcAzg+JiYmJCk4th58sknJUnf+c53Zrx/ZGSkfBZV9Po+aUl6+eWXJVU5hzOEmEal\n7B1XQcitxx57TJK0e/duSdIPfvADSVU8cdnhGGm1WiXXGEtPnTolSTp+/Lgk6eTJk5Kqve1x9vQH\nV53JUVQtlC4g727evFn+m9/ld9atWyepijf9e3gk9jgMmCeTmwvHXXecJsIYu2vXLkmV6+7RRx/t\nmA9XrVolqZpDcWd9+OGHkir3FrlJDp89e1aS9K9//UtSdVIJcQ3zw+dNYkkMDxw4IOmOk5JcxK18\n8eLFGc9xLee0mMXDFeW59FKaLR6J1+Li94usRRk/WavyuGfPHq1du3bGZ7B2YXw8duyYpGrNwxqV\n+ZHx1nM0sW8e4ssY6+ugOu7cIT79jlMcISGEEEIIIYQQQhgYGnWEuPJFZe+HP/yhJOnXv/61JOnF\nF1+UpFLVa7VaRX2kKohiglqGEoZi+tprr0mqqvAoX6no9R/f+4qqNTo6qk2bNkmqHCEbN26U1LmX\nPTSLq5Rcd3p/oFbu379fUuXS4v31vZOex7gSvHcI6qX3nPAqbpgd4se4Rx498cQTkqTHH39cknTo\n0CFJldMHZwBxrJ9Owc9wi6CwoHaifhJnV01whmRM7Y1uJ1IQFxxW9I8gB3HPXb16tfQhIL6cXPHo\no49KquZHchB1mkfoprCEuePKJesXXAPPPfecJBVXJD0lxsbGyhxZ7/8iVU4OHDz107vqr+MywAHE\n94H3+d73cG+8Pw8OPPKL8ZaeWsPDw8WFQ68s+p+hQtP/LI665vG+Ea4qe97wPqjHwk+iJGfIIVRp\nPxUvPbSahRix5mFO437xqaeekiT9+Mc/llT1uRsbGyu/SywYR1k3sWbls5l7yVnvJeI9CxPj3vG1\nLOtMeoJyT7Jz586y9mHMZIylD+Hp06clSR988IGk7n3tFvxvbuRTQgghhBBCCCGEEO4DGpHpvbpO\nJQgFkooePUFwd1B1+/TTTzv2NPupF88+++yM36GCRw8RnmevbP/xfVp1VaXea0LqVKyiRPaHbic0\noXTxOvlBRRz1uV4BJ3+JJY8ooKhkVNfPnz8vqdOdFeaOnzyBosG19y7pXGN6JVEhr/eAIPb8LmMq\n4zInIuAe4LtAp3U+KznbG+SkO0Lo94IjBMUEJw4qx/Xr14tS4g473AY4Qjy/cZIwr85l73y4O93W\nN/RXQulinYPjinhPT0+XuKBoERfiROwvXbokqRpTUcJ4nV4h5H9yc2G4e5meS7h8eP3KlSvl5Dsc\nIe+9956kyo3lDrqoyr3T7UQm5jKUZBwA7gRg7nPXcqvV6nDqESfv00POoU77/BgXVm94zwhiRg+Q\ngwcPSqp6ShJbfu/jjz8uvZGYK90JxPeEtSqx9VNHGZf5nIynvcO1596DefCFF16QJP385z+XVPW3\nW7t2bYkb15240r/uz3/+syTp9ddfl1T1ZWrafRdHSAghhBBCCCGEEAaGRhs3UHWlis7+dtwc3msA\nJfLkyZNFEeFnVAFRvniO6kKX4AsXLkjqPI0k+zMXj/q1Ri2jOkjltVuX5tAMrlrynL3lOEB4zvuo\nqBKfdrtd1BYqulTV3RnC+1CjvXcMj4n17Pg1Iy4oxpweQfzIL1c66vHFecCe2+9973uSqnGaXhXE\nFRWN70boDY+ln/jCXmecObzOOIoiKXXuiccZQt8Xd1eS576HOvvbF447e+gnQRxZozAesia5cOFC\nWafwyHoHZYtH8h1lDBX62rVrkjoVzcS1N9zdwxyHa5lYMp5OTk6WEyhwQhIj3HiJQXO4usy9A6em\ncV/AnIYri7GVNQouSOa8drtdYu9rJeZcVOc33nhDUjVPHjlyRFLl0iIX4yKYG+7yYb1BvzocdsSU\n2HOdcb8eO3asuI+JK/nK7zIv8jox5HXGcO8RQg4npnPH40mO4gD57W9/K6nKWb4Hn332Wck5dwnR\nAw+XEPf7rHe7OXp6JSveEEIIIYQQQgghDAyNOEK8PwFKCfstqdKhqKByvPLKK5Kko0ePFiWL97Bv\nms7BVOpRwn7yk59IqvbvoaKlY3f/oaLn++qGh4dLpRWVBIUrp/r0F69kU+lGtaJy6ioIcSJvhoaG\nikMA6OaNA8RPdIrzY+GQS8SBfed00aYiTu8A4sv7eWT8XL9+fYmPqx18F/gdP7s9Y2cz+LzInIZq\niWMHUBrrJ4oQI/Kaz0LpIlcZZ8lFPx0m+9l7x509KJX0a8ERgluH/OI0kZdeeqn0l6DHBw4QHAfE\nmTjxOp/Fo/faSq72BrmJc4DT1FAzUSZx8Jw4cUInTpyQVI3NxMQdYCikfjpJ3DtzB6WftQauAZwh\n3FNwug9qs69R4G49IPzkGRRt72tHzjI+c6/iLucwN8gP3Drei47YMyYyVnJS6OTkZLmHxOlB7jG3\n+pjNZ9Z7xdQfs4adP76+4d6c09N+9atfSaqcPqxhcdYdOXKkOB2JG+5ld/hQU3j//fcldTrcF7rT\nII6QEEIIIYQQQgghDAwLcoR4XwLcACgkdN5GQaGCztnAr776anlOlZ3KLZVflE+qh+zxeuSRRyRJ\nhw4dkqSiuFB1igLWPH7ygJ/t/uCDD5Y4EUeq5lTuEo/+wPVG3WcPOs9RSDyGxId8GRkZKed8U5En\nvuDuk5zBvnC4ZjinUEF4juPN3VjefwKF5LHHHisuOqrp5CZjLUoXriHGzvTxWRjdThlB1WR+5DnX\nnVxlT/S1a9c6TmDC5cP8yGcTW9/vzmfGOdA7xBE1ERcBMUAJQ1kmZri3Ll++XJQvnw9Z3/C6O0Pc\n+eFxTI7OD2JJvuAAef755yVVMSUHOb3g9OnTRYXkmvMZ5CDKKPMlsSPWHuM4RGbHnZJcQ+ZH+gwS\nC6414JQjnp9//nm53sQaNwkOLyCuPDLX8h1K3OaHO6fATw6pOyKlKnb1PhGMj8SdMZlHcpH4e2+J\nu52yF+ZH/bRQqXJn0RuEdSdz31//+ldJ1UkwU1NT5btAP1Fy0Hu7MMfynLm2qX6EcYSEEEIIIYQQ\nQghhYGikRwhKCfvzduzYIalybQDK4+HDhyVVLo7Lly93KF/uIKASxBnEVJsmJiZm/M133nlnxu9n\n/17zeEUXBWT9+vUdqhjVwHRW7y9cV99XSTXd9y/7aRL13jxU2elpQEx5L5/pe2WjOveOO3oYt9yV\nw1iLyw41iy7bVNYPHTrU4QQhTozD9DC4dOnSjJ/HTdcMxAynJKoGe2Z5nXigXuHm+vLLL8v3ANWF\neRDlyxVTV5/dEZKYzh1Xm7zXC44ecpHcZO5D3ZqYmCi/w952xmdOP+CkCtxaOEWIl8ctcewNVEz6\nEXBaDOMnOcvcxgkxH3zwQcfYi2pJDy16xDCXEmPGV/a3k9/pm9YdlHryAPcicM0Y73BM4t7APUB+\nsQ796quvyneA+D3zzDOSqtMtyXPWOcSRz4iLoDd8LGNuY65i/mMuA+ZJ5s12u13ewxpn3759kipn\nLLF77733JHXmoN+XuKs5zI73WaInKI5X1hz08Xz55Zcl3ekJKt2JN+sZ8pZxGecrY6k7Xpu+14gj\nJIQQQgghhBBCCANDo44Q9tzRY4BKHtU2KkNU2anOXb9+veNUCyp1KCVU9uji7SdZoIxSraeKG0fI\n4rFmzZqOjulUeROH/uIngnC9fV8r8XGVE8V506ZNJbfo2Mx7ULBQNVEvu3VPd+dQFJTuuEPHX+da\nUjlHwaTLNqdoUZXfsGFDR78eVBTi6CfN8B3hMSyM+gk+UqVA4g4glsTD47Js2bKijOCuRAFjnvPx\n1RUuz7l0x58/jJmMg8SN9Q3rn2690tasWVPGSJRKd4KcOXNGUuVoPXfunKTO/jGJW2/wvcfdiJtn\nz549kiolkvmT689JIcuXLy+nPLG+5Tlx9tPWWN++++67kqrxwPvAENtQwXjGmIiLxvtIcA35OfmB\ny85Perl161aZF+lpgMvc/zZuFNY5fCbxSy72hrtdWU8yJpI3OKzIK3pO7ty5s4zJuO5Yv+L04LQ9\nxlXy+aOPPpJUxdYdk3E1z46fyMP6BserO5CnpqYkVa4u4r927drSowlnHq4fYu/x6NbbZaG5mBVv\nCCGEEEIIIYQQBoZGTo2hMoRKRYWIqh3Vt+PHj0uqVA/UrFu3bnVU5Kga8TeoFuIIeeqppyRV1SdU\nbBQ0VJpU25unm3o9NjZWVDGqvX4SRegP3WLiz8kLKui4uFCat2/fXlwGqGbkMflKtR0VxhUSdxR4\n1TZV9+74NeJaomSyH5PKORV1HCKMvSMjIx3d1wGFBWUTxcvjidqW/bPzw0+mIMdQr1A73I3F/Eku\nbtiwoex5RrUkZrzuPX7Ib390p1jUzLnjzjauIfmC+5R4u4NkdHS05C9uEvIUNwFxJb/5jLfeektS\nlYMZO3uDGBIjcgzXIznLeoXrzli4Y8cO7dq1S5L05JNPltekKp+BWKGQsiZFIeWkE/pbpOdEJ95H\ngmvENUTZJ0+Y04gX9wu4Deo9B32dgkOPcZh7Bv6G9+3JWrY3PKbEiuvLvR35wpjJ6Xfk6sjISIkd\n8x5OOz6DHQT0QeP1eq+Y+r8luTd3vN+g9+8gV93FyNy2f/9+SXfWMMx7uLNwvuKq5J6DOZY519cz\nC6XRQggXhP8Jvqx8SbE88T/F/8z09HTHzRKfzaTC72Bx44tcX2zU/w2xd/ePbje0q1ev7mhm403f\nQn/x/OFGiJxkMGIrGTfU2Hz37dtXFngUQnxh4As5v1n3Ca+b7TCL+rnDNWa888aM2A59wV9/jevN\nz7i5Jkd9i4YvPhOvucF8yE0vN0o8+nGbTP4sELhJa7fbpeCBdZSf+bYa8tv/pi/eeX9iOXcYzxgH\nucmiIEzTd266yLf6TRy5xBjpjTdZEPqRkax3vPl75tP54UdZU4gib7juLLRZgHOTvHXrVh08eFBS\nFSti6Y2J/Uhz5la+L9y0E9tsV+sO18S3Efk2XcY57gvIn7uJNMx/FKqID4UQL1ixJYZ/gx+P3pQ9\nf1Dw8ZTiBNsEyVHu6YgPa9b6FnzylvtDtkJR+OCes9tWmMRu4XBNGc8oJjMOsmbxxv/r1q0rP9uy\nZYukKua8h9+hGTL57keQL5RUC0IIIYQQQgghhDAwNNIslcqPW32pmPrxSHUniDTTruZ4E0gqQW6N\ncatUaB53G3gDsroKjYLFYxTIxcEb9nE8lTdApcqO+wOVa9u2baUqC+Stqy/EH/WZyjDfB3LU1Rw/\nHi3MDuOcKx/kHLGpb7tAdUaB5LuAUsl3BLcBlXz+hh9nlxy+Nz4u+pHHfkQy8yVbZji+sd44nFwi\nrjgIvOkxkP/8TX6fedHfH2bHmw2jTp0+fVpStb4hr3zN0m63O8Zl1GjGXdx3bJVBycTijRvPFe4o\nmXOD608eMceRD6xTcBKwhsUxuWfPnpKnxOD8+fOSqkMAyEk/0ty3vvG341qeHXcfe1Nocs/zgvcx\n/sGKFStKfGiUy3PGTD+y1xuxZgxdGN2O0fXmtKw/cIzUtwe6q8SPj/dm4e66yrjZO56TrBeZsxgP\nmctwe3gz6fq9um9x4bOJPfMfa1SPb5qlhhBCCCGEEEIIIcyRRu0TVFRRusAb/3VTs+76D7RGrFT0\nfX8eewa7HRsYmof40XdieHi4o0pIXFJF7y9+HC7qP2o/TTUnJiYkVf0h6E/AXmgUS6mqrvvePnKQ\n3yHm5CiqGrH3yn4aGHfHXQWAukxFHKUY9YR9tfWjPL1fBBV6muFynCvfFfZronizp51cztg6N1zp\nIh84wg9lBBcAqqUfX3y3xn7eO4vcwiFErLwpXGI3f7wXAOMc8SQ/yEncWe6Aa7fbZR1D7HHmMd7y\nXfAeTrgQ+I5kHu0N5i6/ju5a5H04dsiXdevWlfmMZv8cC0nPGPqO0BzZVWj+Rpptzp9uvULA3Xfu\nEOdxdHS0uLCefvppSdW6hfym1wHzIHNsjrDuL8QIBxXOKdYv5M3169c73Ko4g1jLsDZl/GSM5n3e\nQD7MH+/PwpqUuBEbYgDk8BdffFFcQNyH4Fz3JrjkYL/WM3GEhBBCCCGEEEIIYWBoxBHie2j9uEXf\nI4lyQtXnbnvP6xVcqdpnhFKC2kmV0PsXpOref9yt02q1ynWngpc4LA7eFR9Fi33KBw4ckCTt3btX\nUqVeoVDWXVx3UzSlKhf9NBnymcovThKq8Ozvo4JMNT904v0lvLeD5xfX2JXioaGhoo7Ru4B4ka/e\nKwQlk/iiqqCMhXvjThDyAKUE2HtODnpPLX5/5cqVRSnZt2+fpErRJkdxJdCv4t1335XUeeSj9+UK\ns+MnNfFITuIQwBHgPWDqqpWvZ8hN+g8A4zduLdRQ3h96g/HRewq4s4Axkd5ZOKtarVYZaxkPUSv5\nHRx19N/i+0Iu4jTwUxPjMJg7nmN+fDjP3SEC4+PjxSVL/xfeQ5xOnDghqXL+EPe4zpvBXa9+siFj\nH+4A8ov59OLFi2VOJc5+ChT3i9wX8uinCfnpMWF2fJ3DGElvEK4t637WkcSqPgbzWX4KEDnG/Nhv\nV1YcISGEEEIIIYQQQhgYFuQI8c697L+i6kbFj4oe6hbKcf193kcEZYSqIL0N9u/fL6lSoanOs0ea\n6lT2gPUPPy2m3oHdO0D7nlzfNxuaodupBOxFRwXhdWLmpyzdvn17RnduSR0nV6CkoHjhIMDpgeKF\nAsbn0FU6se/EnSBcc66x95Egz3zfed2N572YiI+roHy2u4NyAldv8H1nDGRu4vozt7kzEmWM52vX\nri2OLvY+87vMtW+99ZakyhmC8tXthLY4QmbH+y0xpjJm4qgCP3EERax+Ohax5ZExEDcQcSX23pck\nvUEWBteRvGGOIl/on8TalF4tKJK3bt0qv4MrmbkUxZP1LetdfndyclJSdcpMek7MH79GzHd+goXf\nR7h7Y2xsrDh2yGPew/oERwjjNk4Qd6HkBJLe8N5L3tcORwjrTMZEnJRHjx7V2bNnJVXjJg4ufhd3\nK498Ni4F1ka+eyHMHfKA/Pjkk09mPCd/6icZSjPXrIyh9CzkZ8ydjJWM2573TRFHSAghhBBCCCGE\nEAaGRh0hVOyorHJON4oKpxWw947qD1V5qVIncYIcPHhQkvSb3/xGUrX3i6oTihh7pNnPF+WrebpV\nclFApqeny3cBJdJVTip6cYY0Q7f9lqgdVNWplNdP+JE61Y1vvvmmo68LsaOy66+7yga+FzoKWHeI\nH9eUMRPFmBzDRcA19BN56ntfyU/2z/IdQBHzEymIl3diT9zmhyslzHM4BrqdmsbrxHjz5s1FbUYZ\nIUZ8Fv0pUJ/9b2YPdO94Xw/WJKiMxIs8Yf3DeqauYpGL7tTD6Up+++lQntdRoXvDT1lijUpPHZxX\nuOKYJ3m8efNmcXjhHnFnLLlG/I8dOyZJeuONNyRJb775pqQqpumfNn/8e+/jm68vWecwj27cuLH0\ncvH1C84d7inuNqfe698S5oa7XxkbmesYI3FxEB9cj1NTU8V9QH7yO9ybkMeMq4zh8zmxNNybbj3R\n6qfCSDPv76Xq2q9atarE3Ht+EnPWPaxr+pVzcYSEEEIIIYQQQghhYGjEEULFlD1BR44ckSQ98cQT\nkioXB+rHL37xC0lVxe/KlSul2kqFiC75zz//vKRK2eZvUtH/+9//Lkk6deqUpKoKFUdIc7jrwM/7\nrp/DzncBZct7Ufie9ThDmsV7RaDmUymnIs5zrn+9WzM55CdO+H5K38fO+1FSUK9RSvl5Yt0drin5\ngqKBgoy7w89ZxxHAtV+2bFl5L7/73HPPSZIef/zxGZ/NZ7B/9vLly5KquKXf0vxwpYT88OvYzc1F\njtY/C4XEnQK87nvl3TmQnJs/fgIF6iPuAZ77yXXkDWpWu90uuche9hdffFFS1buJ2DNmcioC6xzU\ntqxresOVxjNnzkjqdN4RB2LM+mXlypUdPSWYWxk/Wf8ePnxYUrUOPnr0qKSqn527e0Lv+DXkOfMo\nj7i4tm/fXnqauYPn5MmTkqo4dusJEprB1zq4ArxfErnL3Hf79u2OexDcyuQz4K70tWrG0ebxdQ6P\n3dY5q1ev7nDu+KlezIfu9IKmcjKOkBBCCCGEEEIIIQwMjRwLQIWcit3rr78uqeoR8stf/lJSpWb+\n9Kc/lVR1ir127Vqp2OEIoWpLxY/qEkrJH//4R0nSSy+9JKlSX7Lvsn8QIyp6qCXEqH4uNBVbXD/s\nA2SvV5wgzcJ15PqiGF+4cEFSpfKjahEPqrj1CiynvXjHZledUSn5W6iXly5dmvG3cRqQw4l5J17p\n5jlKB+oz/T1w2ZGT7t554IEHyikGnHLAc2Lvp5qwp5290uzDTWf13nA3RrcYuzuLsXPFihUdji1i\nVlfHeG/9d8PC4doyphInxlBcq6jNjIuMhzy2Wq2Ok0V4TrxwdL399tuSOtXpuAgWhvezY25jzEN5\nZA579tlnJUl79+6VdEexJFbkIPMkPSVwfkxNTUmq+o8Q2269JsLC8THWcxUn1q5du0pPF/KamJNr\nvt4Ji4PHECceLo/du3dLujNmkoP0baLvi8eWR1xbPO/X6SODiMfNn3frCbNu3bqOnoV+/0Kc+93b\nJY6QEEIIIYQQQgghDAyNyEdUgKjeUCH/05/+JKmq0r3wwguSKpcA1aBWq9VRPaJqTpdvVMrf//73\nMz4b9TknGyweVNuJa73DLxV44D2uVGbvejO4S4McPHfunKRKEaHi6t22qYzz+tWrV4t7BNW5W18X\nnAI4Q3B+cJIFe2/5HHI0dOJx5Np6XwncVyggKMyoJlTbV61a1XFiE5+N+skpBn/5y18kSf/4xz8k\nVd3Z+92pe9CYrzOE51LnyTN+Oprvifc90Ynh3OFakXvMbyjGuFXpvUMucgoTOViPBTmIskU8cRXg\nIsDh6k6F9OlpBj/RiTnLHTl/+MMfJFWnT2zcuLGMse78oScMcyg5igMk6nP/8TGzfvKWVDkHNm/e\nXOJAbuHcwSUUx05/8bUOecL1J58YdzntjnF39+7d5TMYT/ksxlPWsO6IdldWcrJ/dHOCsJPg4Ycf\n7ujNRMy57/cdBl4naGpnQRwhIYQQQgghhBBCGBgadYSgclDZe+WVVyRV6hWduukRsn37dkl39sG7\nA+T8+fMzPuOf//ynJOn48eOSqko+fzOVvf7hFVzfr44rZ3JyslRvid/FixclVZW+VGL7g/ft4LqT\nTyhdr776qqTKWeBK840bN0pcqZ57l3wHxYvvBWob/5bsjZ4dH0PJF8Y54oUqiasOxZJH3jcyMlI+\nC6WSnKSH04kTJyRVbjv6L6F0pjdIf+i2p9Yfv/7665JLxLDbHtpusco42zuMa1xr8ofXGd9wExw4\ncEBSdcIdbrxWq1Xey1oIdwnrmtdee01SlZMomH4KXuLZDH6yk/eDYQ1bVx67qZDdYpNYLT6oz/TW\n2rZtm6TKVTAyMlLWOoyprJW8f13oD+QL60nGV5yo9E/yNQ2xHB8f7/gMXCT0VuLEptOnT0uq1lFZ\ni/aPbo5X7y3JqUDj4+Plv1qnXx4AAAM5SURBVJkfuV/h0d0kdZdsk8QREkIIIYQQQgghhIGh0Rbz\nvrcWpYRz1U+dOiVJ+t3vfiep2ls7Pj5eKvJUgujkTJ8BXqdqm4re4uP7a+lDQU+Iw4cPl/1fKF/E\nj4pf4tYf3FFAld3ziRz0yurdVBBXtFz56tbnZbafh05coXQngO+jJedwd6CicB57q9Uq72Xf7Icf\nfiipUl68F0zG1sXF88PdQFevXi09log/e2UZT70fT/oSNIfPd+QR8UGFxG2He5W97Li2hoeHiwpN\nXwJyjzmUz2bczl72b5fMXfcXrGdQjumBhpuAcfPGjRtlbMTJzH0KOZqYLw7uYmY8pVcZrjl6mXFq\nzKZNm4pTgDUObj36vbD7gHmR2GYHQf+Zbewkdu12uzgeWcfg8OnWG6tfp+LFERJCCCGEEEIIIYSB\nYehelbGhoaElWzZrt9sDsxFwseJYdxUsVsV1UOL4beRiUx2ZZ2NQYijNP47eDZ9HKuM88nr9vHXv\n6eO9XLo5fHplUOLYr1z0WI+MjBRHCEpnt1OFUFKIca+unkGJodR7HL1XBDnHo+fq8uXLSzx4JE7E\nMbnYG1mjLg0WmovkHo5kTnTasWOHJGliYkJS1WdCks6ePSup6suD8wB3Fmr1Qt11gxLHpnLR50Ef\nX1ut1gxXgVTNfz6eNuWoG5QYSs3F0deqrGXWr18vSdq6dWs51WnDhg2SqnUO8cTRg5MdZ3uvPSe7\nxTGOkBBCCCGEEEIIIQwMcYQMAInj/U9iuDRIHO9/EsOlQeJ4/5MYLg0WGkccApxCQX8elGb6EW7e\nvLn036Fn1oULFyRVJ4t4n564CeZGcnFp0HQc3bVVPz2GUxDd/UPO4cqi16E7X+dLHCEhhBBCCCGE\nEEIYeOIIGQASx/ufxHBpkDje/ySGS4PE8f4nMVwa9Ku/RLeeWlJnnyXvK9EUgxLH5OLSYBDjGEdI\nCCGEEEIIIYQQBoZ7OkJCCCGEEEIIIYQQlhJxhIQQQgghhBBCCGFgSCEkhBBCCCGEEEIIA0MKISGE\nEEIIIYQQQhgYUggJIYQQQgghhBDCwJBCSAghhBBCCCGEEAaGFEJCCCGEEEIIIYQwMPw/4anSJGn2\nwhsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TumnnA2iJSAX",
        "colab_type": "text"
      },
      "source": [
        "# UMAP\n",
        "These links help you to understand how UMAP works.\n",
        "\n",
        "[Scanpy anndata](https://anndata.readthedocs.io/en/stable/)\n",
        "\n",
        "[Scanpy umap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.umap.html)\n",
        "\n",
        "[Example](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUh9l9yeJSAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create latent space and labels for UMAP\n",
        "cvae.eval()\n",
        "latent = None\n",
        "labels = None\n",
        "with torch.no_grad():\n",
        "    for data, cond in test_loader:\n",
        "      if data.size() == torch.Size([128, 1, 28, 28]):\n",
        "        data = data.view(128, 28*28)\n",
        "        data = data.to(device)\n",
        "        \n",
        "        if labels is None:\n",
        "            labels = cond\n",
        "        else:\n",
        "            labels = torch.cat((labels, cond), 0)\n",
        "            \n",
        "        cond = one_hott(cond) # create one-hot condition\n",
        "        cond = cond.to(device)\n",
        "\n",
        "        # recon_batch, mu, log_var = cvae(data, cond)\n",
        "        # batch_latent = cvae.sampling(mu, log_var)\n",
        "      \n",
        "        batch_latent = cvae.encoder(data,cond)\n",
        "\n",
        "        if latent is None:\n",
        "            latent = batch_latent[0]\n",
        "        else:\n",
        "            latent = torch.cat((latent, batch_latent[0]), 0)\n",
        "labels = labels.detach().numpy()\n",
        "latent = latent.cpu().detach().numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z75FPnUAEcJf",
        "colab_type": "code",
        "outputId": "79896123-5e52-4a4e-f689-67e1107f2b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install scanpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scanpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/73/569503d8c99ae28b94325363e3f60a15105785802c918d44a2e69a9bcffa/scanpy-1.4.5.tar.gz (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 4.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py!=2.10.0 in /usr/local/lib/python3.6/dist-packages (from scanpy) (2.8.0)\n",
            "Collecting legacy-api-wrap\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/68/da997bc56bb69dcdcee4054f0bc42266909307b905389fbc54c9158f42da/legacy_api_wrap-1.2-py3-none-any.whl\n",
            "Collecting anndata>=0.7rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/aa/5391f687bda6fbfc0fbdc24863b836954cb2ab73657cb324f10e319be06f/anndata-0.7rc1-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from scanpy) (4.28.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from scanpy) (3.4.4)\n",
            "Collecting numba>=0.41.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/7d/f2b5ea8d5952115351e303d1aadbdd1c5b08f479d76456d43a5d7a3a8c88/numba-0.47.0-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 70.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.21.3)\n",
            "Requirement already satisfied: umap-learn>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.3.10)\n",
            "Collecting matplotlib==3.0.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0MB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from scanpy) (2.4)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.6/dist-packages (from scanpy) (5.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.14.1)\n",
            "Collecting setuptools-scm\n",
            "  Using cached https://files.pythonhosted.org/packages/1d/70/97966deebaeeda0b81d3cd63ba9f8ec929b838871ed17476de9d8159db3e/setuptools_scm-3.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=0.7; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from scanpy) (1.3.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.9.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from scanpy) (0.25.3)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.6/dist-packages (from scanpy) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py!=2.10.0->scanpy) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py!=2.10.0->scanpy) (1.17.4)\n",
            "Collecting get-version>=2.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/48/7610e884e62fff2183e7bc8592397c39a020267fb5147905fcd3f9cc820c/get_version-2.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from legacy-api-wrap->scanpy) (42.0.2)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->scanpy) (2.7.0)\n",
            "Collecting llvmlite>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 109kB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.*->scanpy) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.*->scanpy) (2.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.*->scanpy) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.*->scanpy) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->scanpy) (4.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.7; python_version < \"3.8\"->scanpy) (0.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->scanpy) (2018.9)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.7; python_version < \"3.8\"->scanpy) (8.0.2)\n",
            "Building wheels for collected packages: scanpy\n",
            "  Building wheel for scanpy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scanpy: filename=scanpy-1.4.5-cp36-none-any.whl size=264431 sha256=d79f9b5a5bd37c222ed3a4d702bc555b38651abba84b9ae9f767af6d9f1c3d2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/4e/27/5681d399489fed5e4d777bb8027afea4c0a4aeb7e89e789150\n",
            "Successfully built scanpy\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: get-version, legacy-api-wrap, anndata, llvmlite, numba, matplotlib, setuptools-scm, scanpy\n",
            "  Found existing installation: llvmlite 0.30.0\n",
            "    Uninstalling llvmlite-0.30.0:\n",
            "      Successfully uninstalled llvmlite-0.30.0\n",
            "  Found existing installation: numba 0.40.1\n",
            "    Uninstalling numba-0.40.1:\n",
            "      Successfully uninstalled numba-0.40.1\n",
            "  Found existing installation: matplotlib 3.1.2\n",
            "    Uninstalling matplotlib-3.1.2:\n",
            "      Successfully uninstalled matplotlib-3.1.2\n",
            "Successfully installed anndata-0.7rc1 get-version-2.1 legacy-api-wrap-1.2 llvmlite-0.31.0 matplotlib-3.0.3 numba-0.47.0 scanpy-1.4.5 setuptools-scm-3.3.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZpEOTC-JSAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UMAP\n",
        "import scanpy as sc\n",
        "\n",
        "labels = labels.astype(str)\n",
        "latent_anndata = sc.AnnData(X=latent, obs={\"Numbers\": labels})\n",
        "sc.pp.neighbors(latent_anndata)\n",
        "sc.tl.umap(latent_anndata)\n",
        "\n",
        "# Visualization\n",
        "sc.pl.umap(latent_anndata, color=[\"Numbers\"],\n",
        "           frameon=False,\n",
        "           legend_loc=False,\n",
        "           show=True)\n",
        "print('KL Coefficient:1, Reconstruction Coefficient:1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C48F2_R7fR7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UMAP\n",
        "import scanpy as sc\n",
        "\n",
        "labels = labels.astype(str)\n",
        "latent_anndata = sc.AnnData(X=latent, obs={\"Numbers\": labels})\n",
        "sc.pp.neighbors(latent_anndata)\n",
        "sc.tl.umap(latent_anndata)\n",
        "\n",
        "# Visualization\n",
        "sc.pl.umap(latent_anndata, color=[\"Numbers\"],\n",
        "           frameon=False,\n",
        "           legend_loc=False,\n",
        "           show=True)\n",
        "print('KL Coefficient:0.07, Reconstruction Coefficient:1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HggpPNh_hiwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UMAP\n",
        "import scanpy as sc\n",
        "\n",
        "labels = labels.astype(str)\n",
        "latent_anndata = sc.AnnData(X=latent, obs={\"Numbers\": labels})\n",
        "sc.pp.neighbors(latent_anndata)\n",
        "sc.tl.umap(latent_anndata)\n",
        "\n",
        "# Visualization\n",
        "sc.pl.umap(latent_anndata, color=[\"Numbers\"],\n",
        "           frameon=False,\n",
        "           legend_loc=False,\n",
        "           show=True)\n",
        "print('KL Coefficient:1, Reconstruction Coefficient:0.07')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}